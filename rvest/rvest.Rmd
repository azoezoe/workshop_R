---
title: "R Notebook"
---
```{r}
install.packages("jsonlite")
install.packages("rvest")
```

```{r}
library(jsonlite)
library(rvest)
```

# URL encode（把文字變成網頁編碼）
```{r}
URLencode("亞洲水泥")
```

# URL decode（把網頁編碼解碼成文字）
```{r}
URLdecode("%E4%BA%9E%E6%B4%B2%E6%B0%B4%E6%B3%A5")
```

# 打 API （讀取 json）
```{r}
json<-fromJSON("http://company.g0v.ronny.tw/api/search?q=%E4%BA%9E%E6%B4%B2%E6%B0%B4%E6%B3%A5&page=1")
```

# 抓取想要的欄位，組成表格
```{r}
company<-data.frame(
  公司名稱=json$data$公司名稱,
  統一編號=json$data$統一編號,
  資本總額=json$data$`資本總額(元)`,
  代表人姓名=json$data$代表人姓名,
  最後核准變更日期=json$data$最後核准變更日期$year
)
```

## 指定其中一筆
```{r}
company<-data.frame(
  公司名稱=json$data$公司名稱[1],
  統一編號=json$data$統一編號[1],
  資本總額=json$data$`資本總額(元)`[1],
  代表人姓名=json$data$代表人姓名[1],
  最後核准變更日期=json$data$最後核准變更日期$year[1]
)
```

# 利用 company_list 的資料，抓清單上公司的資料
```{r}
company_list <- read_csv("company_list.csv")
```
## 先寫好一筆資料
```{r}
json<-fromJSON("http://company.g0v.ronny.tw/api/search?q=%E4%BA%9E%E6%B4%B2%E6%B0%B4%E6%B3%A5&page=1")
company<-data.frame(
  公司名稱=json$data$公司名稱,
  統一編號=json$data$統一編號,
  資本總額=json$data$`資本總額(元)`,
  代表人姓名=json$data$代表人姓名,
  最後核准變更日期=json$data$最後核准變更日期$year
)
```

## 放進迴圈
```{r}
all_company<-data.frame()

for(n in 1:3){ #n 會在每次迴圈從 1 到 4

print(n) #顯示是第幾次迴圈
  
json<-fromJSON(paste0("http://company.g0v.ronny.tw/api/search?q=",URLencode(company_list$公司名稱[n]),"&page=1"))
company<-data.frame(
  公司名稱=json$data$公司名稱,
  統一編號=json$data$統一編號,
  資本總額=json$data$`資本總額(元)`,
  代表人姓名=json$data$代表人姓名,
  最後核准變更日期=json$data$最後核准變更日期$year
)

all_company<-rbind(all_company,company) #把這次做的表格跟之前的組起來

Sys.sleep(1)
#每打一次休息一秒
}

```


# 靜態網頁爬蟲
- read_html  從指定網址讀取 html 文件
- html_nodes  讀取 html 文件中指定的位置
- html_text  將指定位置裡的內容轉成文字
- html_attr  存取特定標籤的內容
- data.frame(欄位名=值) 將資料組成表格

## 檢測有沒有抓到對的 html
```{r}
html<-read_html("https://www.readr.tw/category/all")
grepl("柬埔寨",html)
```


## 先寫一頁
```{r}
html<-read_html("https://www.readr.tw/category/all")
title<-html_text(html_nodes(html,'.title p'))
url<-html_attr(html_nodes(html,'.iXRvFJ'),"href")
date<-html_text(html_nodes(html,'.date'))
readtime<-html_text(html_nodes(html,'.read'))

title<-title[1:10]
url<-url[1:10]
date<-date[1:10]
readtime<-readtime[1:10]

data<-data.frame(title=title,url=url,date=date,readtime=readtime)

```

## 放進迴圈
```{r}
data_all<-data.frame()

for(q in c("breakingnews","humanrights")){ 
  
  html<-read_html(paste0("https://www.readr.tw/category/",q))
  title<-html_text(html_nodes(html,'.title p'))
  url<-html_attr(html_nodes(html,'.iXRvFJ'),"href")
  date<-html_text(html_nodes(html,'.date'))
  readtime<-html_text(html_nodes(html,'.read'))

  title<-title[1:10]
  url<-url[1:10]
  date<-date[1:10]
  readtime<-readtime[1:10]

  data<-data.frame(title=title,url=url,date=date,readtime=readtime)
  
  data_all<-rbind(data_all,data)
  
  Sys.sleep(1)
  
}
```

